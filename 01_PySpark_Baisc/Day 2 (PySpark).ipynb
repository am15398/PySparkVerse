{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23699674-3c23-439a-a0a2-69d18988d60b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"Day2\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f11e5842-7746-439e-ba5d-387da1acf25d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------+-------------+\n|   name|       dept|salary|         city|\n+-------+-----------+------+-------------+\n|  Alice|         HR| 50000|     New York|\n|    Bob|Engineering| 60000|San Francisco|\n|Charlie|         HR| 55000|  Los Angeles|\n|  David|Engineering| 62000|      Seattle|\n|    Eva|    Finance| 70000|      Chicago|\n|  Frank|    Finance| 75000|      Houston|\n|  Grace|Engineering| 65000|       Boston|\n| Hannah|         HR| 48000|        Miami|\n|    Ian|    Finance| 68000|       Dallas|\n|Jessica|Engineering| 63000|      Atlanta|\n+-------+-----------+------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Sample data \n",
    "data = [\n",
    "    (\"Alice\", \"HR\", 50000, \"New York\"),\n",
    "    (\"Bob\", \"Engineering\", 60000, \"San Francisco\"),\n",
    "    (\"Charlie\", \"HR\", 55000, \"Los Angeles\"),\n",
    "    (\"David\", \"Engineering\", 62000, \"Seattle\"),\n",
    "    (\"Eva\", \"Finance\", 70000, \"Chicago\"),\n",
    "    (\"Frank\", \"Finance\", 75000, \"Houston\"),\n",
    "    (\"Grace\", \"Engineering\", 65000, \"Boston\"),\n",
    "    (\"Hannah\", \"HR\", 48000, \"Miami\"),\n",
    "    (\"Ian\", \"Finance\", 68000, \"Dallas\"),\n",
    "    (\"Jessica\", \"Engineering\", 63000, \"Atlanta\")\n",
    "]\n",
    "\n",
    "# Define the schema for the DataFrame\n",
    "schema = [\"name\", \"dept\", \"salary\", \"city\"]\n",
    "\n",
    "# Create the DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7b04d75-3fcc-4ff0-b83e-af469ad08b58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------+-------------+-----------+\n|   name|       dept|salary|         city|running_avg|\n+-------+-----------+------+-------------+-----------+\n|    Bob|Engineering| 60000|San Francisco|    62500.0|\n|  David|Engineering| 62000|      Seattle|    62500.0|\n|  Grace|Engineering| 65000|       Boston|    62500.0|\n|Jessica|Engineering| 63000|      Atlanta|    62500.0|\n|    Eva|    Finance| 70000|      Chicago|    71000.0|\n|  Frank|    Finance| 75000|      Houston|    71000.0|\n|    Ian|    Finance| 68000|       Dallas|    71000.0|\n|  Alice|         HR| 50000|     New York|    51000.0|\n|Charlie|         HR| 55000|  Los Angeles|    51000.0|\n| Hannah|         HR| 48000|        Miami|    51000.0|\n+-------+-----------+------+-------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Average over partition \n",
    "df.withColumn(\"running_avg\",F.avg(\"salary\").over(Window.partitionBy(\"dept\").orderBy(\"dept\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9e73e52-6666-42e8-8b42-e2263701f2f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------+-------------+-----------+\n|   name|       dept|salary|         city|Running_sum|\n+-------+-----------+------+-------------+-----------+\n|    Bob|Engineering| 60000|San Francisco|      60000|\n|  David|Engineering| 62000|      Seattle|     122000|\n|Jessica|Engineering| 63000|      Atlanta|     185000|\n|  Grace|Engineering| 65000|       Boston|     250000|\n|    Ian|    Finance| 68000|       Dallas|      68000|\n|    Eva|    Finance| 70000|      Chicago|     138000|\n|  Frank|    Finance| 75000|      Houston|     213000|\n| Hannah|         HR| 48000|        Miami|      48000|\n|  Alice|         HR| 50000|     New York|      98000|\n|Charlie|         HR| 55000|  Los Angeles|     153000|\n+-------+-----------+------+-------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Sum over partition\n",
    "df.withColumn(\"Running_sum\",F.sum(\"salary\").over(Window.partitionBy(\"dept\").orderBy(\"salary\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcf40aeb-bbc9-4a30-ac89-c4f618b84ab8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------+-------------+--------+\n|   name|       dept|salary|         city|lead_sal|\n+-------+-----------+------+-------------+--------+\n|    Bob|Engineering| 60000|San Francisco|   62000|\n|  David|Engineering| 62000|      Seattle|   63000|\n|Jessica|Engineering| 63000|      Atlanta|   65000|\n|  Grace|Engineering| 65000|       Boston|       0|\n|    Ian|    Finance| 68000|       Dallas|   70000|\n|    Eva|    Finance| 70000|      Chicago|   75000|\n|  Frank|    Finance| 75000|      Houston|       0|\n| Hannah|         HR| 48000|        Miami|   50000|\n|  Alice|         HR| 50000|     New York|   55000|\n|Charlie|         HR| 55000|  Los Angeles|       0|\n+-------+-----------+------+-------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# lead function with default value \n",
    "lead_df=df.withColumn(\"lead_sal\",F.lead(\"salary\",default=0).over(Window.partitionBy(\"dept\").orderBy(\"salary\")))\n",
    "lead_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2ab5713-d16c-4ff1-b113-be341e521527",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------+-------------+-------+\n|   name|       dept|salary|         city|lag_sal|\n+-------+-----------+------+-------------+-------+\n|    Bob|Engineering| 60000|San Francisco|      0|\n|  David|Engineering| 62000|      Seattle|  60000|\n|Jessica|Engineering| 63000|      Atlanta|  62000|\n|  Grace|Engineering| 65000|       Boston|  63000|\n|    Ian|    Finance| 68000|       Dallas|      0|\n|    Eva|    Finance| 70000|      Chicago|  68000|\n|  Frank|    Finance| 75000|      Houston|  70000|\n| Hannah|         HR| 48000|        Miami|      0|\n|  Alice|         HR| 50000|     New York|  48000|\n|Charlie|         HR| 55000|  Los Angeles|  50000|\n+-------+-----------+------+-------------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# lag function with default value \n",
    "lag_df=df.withColumn(\"lag_sal\",F.lag(\"salary\",default=0).over(Window.partitionBy(\"dept\").orderBy(\"salary\")))\n",
    "lag_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e43ba61-663c-436b-bf4e-293127503ead",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------+-------------+\n|   name|       dept|salary|         city|\n+-------+-----------+------+-------------+\n|  Alice|         HR| 50000|     New York|\n|    Bob|Engineering| 60000|San Francisco|\n|Charlie|         HR| 55000|  Los Angeles|\n|  David|Engineering| 62000|      Seattle|\n|    Eva|    Finance| 70000|      Chicago|\n|  Frank|    Finance| 75000|      Houston|\n|  Grace|Engineering| 65000|       Boston|\n| Hannah|         HR| 48000|        Miami|\n|    Ian|    Finance| 68000|       Dallas|\n|Jessica|Engineering| 63000|      Atlanta|\n+-------+-----------+------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# drop column \n",
    "lag_df.drop(\"lag_sal\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f39478b-6cb3-487c-8c70-a487fa6bf612",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------+-------------+-----------+\n|   name|       dept|salary|         city|lead_salary|\n+-------+-----------+------+-------------+-----------+\n|    Bob|Engineering| 60000|San Francisco|      62000|\n|  David|Engineering| 62000|      Seattle|      63000|\n|Jessica|Engineering| 63000|      Atlanta|      65000|\n|  Grace|Engineering| 65000|       Boston|          0|\n|    Ian|    Finance| 68000|       Dallas|      70000|\n|    Eva|    Finance| 70000|      Chicago|      75000|\n|  Frank|    Finance| 75000|      Houston|          0|\n| Hannah|         HR| 48000|        Miami|      50000|\n|  Alice|         HR| 50000|     New York|      55000|\n|Charlie|         HR| 55000|  Los Angeles|          0|\n+-------+-----------+------+-------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "#rename column \n",
    "lead_df.withColumnRenamed(\"lead_sal\",\"lead_salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32570f13-f5aa-41df-81de-f5616df792af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------+-------------+--------+------------+\n|   name|       dept|salary|         city|lead_sal|new_lead_sal|\n+-------+-----------+------+-------------+--------+------------+\n|    Bob|Engineering| 60000|San Francisco|   62000|     62000.0|\n|  David|Engineering| 62000|      Seattle|   63000|     63000.0|\n|Jessica|Engineering| 63000|      Atlanta|   65000|     65000.0|\n|  Grace|Engineering| 65000|       Boston|       0|         0.0|\n|    Ian|    Finance| 68000|       Dallas|   70000|     70000.0|\n|    Eva|    Finance| 70000|      Chicago|   75000|     75000.0|\n|  Frank|    Finance| 75000|      Houston|       0|         0.0|\n| Hannah|         HR| 48000|        Miami|   50000|     50000.0|\n|  Alice|         HR| 50000|     New York|   55000|     55000.0|\n|Charlie|         HR| 55000|  Los Angeles|       0|         0.0|\n+-------+-----------+------+-------------+--------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# change column datatype\n",
    "lead_df.withColumn(\"new_lead_sal\",F.col(\"lead_sal\").cast(\"float\")).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day 2 (PySpark)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
