{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b56742f1-69dc-4f42-90b7-06db85701721",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0750222-fb20-48cf-89b0-cdc75c6d240e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+\n| ID|     Name|Marks|\n+---+---------+-----+\n| 19| Samantha|   87|\n| 21|    Julia|   96|\n| 11|  Britney|   95|\n| 32| Kristeen|  100|\n| 12|    Dyana|   55|\n| 13|    Jenny|   66|\n| 14|Christene|   88|\n| 15|    Meera|   24|\n| 16|    Priya|   76|\n| 17| Priyanka|   77|\n| 18|    Paige|   74|\n| 19|     Jane|   64|\n| 21|   Belvet|   78|\n| 31|  Scarlet|   80|\n| 41|    Salma|   81|\n| 51|   Amanda|   34|\n| 61|  Heraldo|   94|\n| 71|   Stuart|   99|\n| 81|   Aamina|   77|\n| 76|    Amina|   89|\n+---+---------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "data=[(\"19\",\"Samantha\",\"87\"),(\"21\",\"Julia\",\"96\"),(\"11\",\"Britney\",\"95\"),(\"32\",\"Kristeen\",\"100\"),(\"12\",\"Dyana\",\"55\"),(\"13\",\"Jenny\",\"66\"),(\"14\",\"Christene\",\"88\"),(\"15\",\"Meera\",\"24\"),(\"16\",\"Priya\",\"76\"),(\"17\",\"Priyanka\",\"77\"),(\"18\",\"Paige\",\"74\"),(\"19\",\"Jane\",\"64\"),(\"21\",\"Belvet\",\"78\"),(\"31\",\"Scarlet\",\"80\"),(\"41\",\"Salma\",\"81\"),(\"51\",\"Amanda\",\"34\"),(\"61\",\"Heraldo\",\"94\"),(\"71\",\"Stuart\",\"99\"),(\"81\",\"Aamina\",\"77\"),(\"76\",\"Amina\",\"89\"),(\"91\",\"Vivek\",\"84\"),(\"17\",\"Evil\",\"79\"),(\"16\",\"Devil\",\"76\"),(\"34\",\"Fanny\",\"75\"),(\"38\",\"Danny\",\"75\")]\n",
    "schema =[\"ID\",\"Name\",\"Marks\"]\n",
    "\n",
    "df=spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "652cdaef-2caf-4eae-94ff-b099a0efe969",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<h2> Higher Than 75 Marks Hacker Rank </h2>\n",
    "<h3> PySpark code Name of any student in STUDENTS DF who scored higher than  Marks. Order your output by the last three characters of each name. If two or more students both have names ending in the same last three characters (i.e.: Bobby, Robby, etc.), secondary sort them by ascending ID </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7d5a282-143b-4387-a4a6-caed9ac3e375",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n|     name|\n+---------+\n|   Stuart|\n| Kristeen|\n|Christene|\n|    Amina|\n|   Aamina|\n|    Priya|\n|  Heraldo|\n|  Scarlet|\n|    Julia|\n|    Salma|\n|  Britney|\n| Priyanka|\n| Samantha|\n|    Vivek|\n|   Belvet|\n|    Devil|\n|     Evil|\n+---------+\n\n"
     ]
    }
   ],
   "source": [
    "df.filter(F.col(\"marks\") > 75).orderBy(F.substring(F.col(\"name\"), -3, 3), F.col(\"id\"))\\\n",
    "    .select(\"name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe91bf0b-1c91-49ba-9516-d29521a4ddad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<h2> Employee Names Hacker Rank </h2>\n",
    "<h3> PySpark code that prints a list of employee names (i.e.: the name attribute) from the Employee DF in alphabetical order </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "704416d2-6c25-41ee-b2c7-b63b8ed4316c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+------+\n|employee_id|    name|months|salary|\n+-----------+--------+------+------+\n|        330|    Rose|     5|  2248|\n|       1233|  Angela|     7|  1296|\n|       1901|   Frank|    10|  2763|\n|       2035| Patrick|     1|  4583|\n|       2405|    Lisa|     7|  4350|\n|       2974|Kimberly|    11|  2874|\n|       3190|  Bonnie|    11|  3758|\n|       3506| Michael|     9|  1936|\n|       3708|    Todd|    22|  4046|\n|       4428|     Joe|    22|  3802|\n|       5962|    Earl|    11|  2958|\n|       6060|  Robert|    22|  4128|\n|       6418|     Amy|     2|  4832|\n|       7466|  Pamela|     1|  4199|\n|       9102|   Maria|    11|  2958|\n|      11863|     Joe|    18|  1721|\n|      12004|   Linda|    15|  2306|\n|      12387| Melissa|    20|  1854|\n|      13835|   Carol|    20|  4340|\n|      15151|   Paula|    15|  1526|\n+-----------+--------+------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "data =[(\"330\",\"Rose\",\"5\",\"2248\"),(\"1233\",\"Angela\",\"7\",\"1296\"),(\"1901\",\"Frank\",\"10\",\"2763\"),(\"2035\",\"Patrick\",\"1\",\"4583\"),(\"2405\",\"Lisa\",\"7\",\"4350\"),(\"2974\",\"Kimberly\",\"11\",\"2874\"),(\"3190\",\"Bonnie\",\"11\",\"3758\"),(\"3506\",\"Michael\",\"9\",\"1936\"),(\"3708\",\"Todd\",\"22\",\"4046\"),(\"4428\",\"Joe\",\"22\",\"3802\"),(\"5962\",\"Earl\",\"11\",\"2958\"),(\"6060\",\"Robert\",\"22\",\"4128\"),(\"6418\",\"Amy\",\"2\",\"4832\"),(\"7466\",\"Pamela\",\"1\",\"4199\"),(\"9102\",\"Maria\",\"11\",\"2958\"),(\"11863\",\"Joe\",\"18\",\"1721\"),(\"12004\",\"Linda\",\"15\",\"2306\"),(\"12387\",\"Melissa\",\"20\",\"1854\"),(\"13835\",\"Carol\",\"20\",\"4340\"),(\"15151\",\"Paula\",\"15\",\"1526\"),(\"15286\",\"Marilyn\",\"10\",\"3087\"),(\"15675\",\"Jennifer\",\"2\",\"2336\"),(\"16493\",\"Harry\",\"14\",\"4755\"),(\"17858\",\"David\",\"13\",\"3658\"),(\"19035\",\"Julia\",\"4\",\"2195\"),(\"19172\",\"Kevin\",\"1\",\"2113\"),(\"21638\",\"Paul\",\"6\",\"3120\"),(\"22684\",\"James\",\"14\",\"1370\"),(\"23621\",\"Kelly\",\"7\",\"1923\"),(\"24011\",\"Robin\",\"22\",\"1880\"),(\"24611\",\"Ralph\",\"22\",\"1495\"),(\"25109\",\"Gloria\",\"2\",\"1979\"),(\"25120\",\"Victor\",\"20\",\"1557\"),(\"28247\",\"David\",\"23\",\"2212\"),(\"30183\",\"Joyce\",\"20\",\"2748\"),(\"30712\",\"Donna\",\"8\",\"2604\"),(\"32502\",\"Michelle\",\"1\",\"2086\"),(\"32654\",\"Stephanie\",\"17\",\"1444\"),(\"33086\",\"Gerald\",\"23\",\"2206\"),(\"33132\",\"Walter\",\"11\",\"4180\"),(\"37008\",\"Christina\",\"8\",\"3100\"),(\"38246\",\"Brandon\",\"3\",\"4339\"),(\"38272\",\"Elizabeth\",\"23\",\"3967\"),(\"38964\",\"Joseph\",\"4\",\"2194\"),(\"39789\",\"Lawrence\",\"9\",\"1872\"),(\"40797\",\"Marilyn\",\"15\",\"2112\"),(\"41228\",\"Lori\",\"13\",\"4350\"),(\"44436\",\"Matthew\",\"15\",\"4673\"),(\"45285\",\"Jesse\",\"1\",\"3768\"),(\"47458\",\"John\",\"13\",\"3104\"),(\"47496\",\"Martha\",\"15\",\"4020\"),(\"47920\",\"Timothy\",\"10\",\"1745\"),(\"48129\",\"Christine\",\"22\",\"3738\"),(\"50664\",\"Anthony\",\"22\",\"4912\"),(\"51741\",\"Paula\",\"1\",\"2492\"),(\"52923\",\"Kimberly\",\"17\",\"1955\"),(\"55238\",\"Louise\",\"1\",\"2717\"),(\"56775\",\"Martin\",\"16\",\"1385\"),(\"57065\",\"Paul\",\"23\",\"3379\"),(\"58343\",\"Antonio\",\"21\",\"3268\"),(\"59256\",\"Jacqueline\",\"14\",\"3913\"),(\"60119\",\"Diana\",\"13\",\"5149\"),(\"61191\",\"John\",\"5\",\"1775\"),(\"65288\",\"Dorothy\",\"22\",\"3792\"),(\"65375\",\"Evelyn\",\"6\",\"4079\"),(\"66442\",\"Phillip\",\"9\",\"1894\"),(\"67137\",\"Evelyn\",\"15\",\"1311\"),(\"68942\",\"Debra\",\"20\",\"3704\"),(\"69085\",\"David\",\"11\",\"1845\"),(\"69234\",\"Willie\",\"12\",\"5088\"),(\"69475\",\"Brandon\",\"19\",\"2279\"),(\"69787\",\"Ann\",\"9\",\"1311\"),(\"70963\",\"Emily\",\"8\",\"5247\"),(\"71569\",\"Dorothy\",\"22\",\"4088\"),(\"72030\",\"Jonathan\",\"4\",\"5009\"),(\"72370\",\"Dorothy\",\"18\",\"3174\"),(\"72785\",\"Marilyn\",\"1\",\"1860\"),(\"72974\",\"Norma\",\"21\",\"1558\"),(\"74662\",\"Nancy\",\"6\",\"3223\"),(\"76876\",\"Andrew\",\"11\",\"1746\"),(\"77609\",\"Keith\",\"2\",\"1219\"),(\"78101\",\"Benjamin\",\"7\",\"4414\"),(\"79744\",\"Charles\",\"11\",\"1911\"),(\"80475\",\"Alan\",\"16\",\"1853\"),(\"80895\",\"Tammy\",\"8\",\"1591\"),(\"81381\",\"Anna\",\"16\",\"1569\"),(\"82828\",\"James\",\"23\",\"4398\"),(\"85287\",\"Robin\",\"23\",\"2078\"),(\"87170\",\"Jean\",\"18\",\"3895\"),(\"87355\",\"Andrew\",\"15\",\"1446\"),(\"89017\",\"Roy\",\"8\",\"3443\"),(\"90507\",\"Diana\",\"9\",\"5101\"),(\"90558\",\"Christina\",\"23\",\"3498\"),(\"92908\",\"Jesse\",\"13\",\"4753\"),(\"95322\",\"Joyce\",\"18\",\"1577\"),(\"95983\",\"Patricia\",\"23\",\"1469\"),(\"96963\",\"Gregory\",\"16\",\"5071\"),(\"97178\",\"Brian\",\"19\",\"3144\"),(\"98271\",\"Christine\",\"3\",\"3796\"),(\"98491\",\"Lillian\",\"3\",\"1920\")]\n",
    "schema =[\"employee_id\",\"name\",\"months\",\"salary\"]\n",
    "df= spark.createDataFrame(data,schema )\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7cf543c-3377-4916-95db-114c8df90a03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n|     name|\n+---------+\n|     Alan|\n|      Amy|\n|   Andrew|\n|   Andrew|\n|   Angela|\n|      Ann|\n|     Anna|\n|  Anthony|\n|  Antonio|\n| Benjamin|\n|   Bonnie|\n|  Brandon|\n|  Brandon|\n|    Brian|\n|    Carol|\n|  Charles|\n|Christina|\n|Christina|\n|Christine|\n|Christine|\n+---------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.select(F.col(\"name\")).orderBy(F.col(\"name\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58787ac6-0bf0-4398-b965-e1ac186d13d3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<h2> Employee Salaries Hacker Rank </h2>\n",
    "<h3> PySpark code list of employee names (i.e.: the name attribute) for employees in Employee having a salary greater than  per month who have been employees for less than  months. Sort your result by ascending employee_id </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcbb1e1f-a730-46d2-95a0-9ea1d76c23fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n|     name|\n+---------+\n| Jennifer|\n|    Julia|\n|    Kevin|\n|  Patrick|\n|     Paul|\n|     Lisa|\n|    Donna|\n| Michelle|\n|     Rose|\n|Christina|\n|  Brandon|\n|   Joseph|\n|    Jesse|\n|    Paula|\n|   Louise|\n|      Amy|\n|   Evelyn|\n|    Emily|\n| Jonathan|\n|   Pamela|\n+---------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.filter((F.col(\"salary\") > 2000) & (F.col(\"months\") < 10))\\\n",
    "    .orderBy(F.col(\"employee_id\")).select(\"name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5af06075-3c59-4b65-981c-888e95ee697b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<h2> Type of Triangle Hacker Rank </h2>\n",
    "<h3> PySpark code to identifying the type of each record in the TRIANGLES table using its three side lengths. Output one of the following statements for each record in the table: </h3>\n",
    "<h4>Equilateral: It's a triangle with  sides of equal length.</h4>\n",
    "<h4>Isosceles: It's a triangle with  sides of equal length.</h4>\n",
    "<h4>Scalene: It's a triangle with  sides of differing lengths.</h4>\n",
    "<h4>Not A Triangle: The given values of A, B, and C don't form a triangle. </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfecf3cf-8f13-4f35-b499-3e621c49ad22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n|  A|  B|  C|\n+---+---+---+\n| 10| 10| 10|\n| 11| 11| 11|\n| 30| 32| 30|\n| 40| 40| 40|\n| 20| 20| 21|\n| 21| 21| 21|\n| 20| 22| 21|\n| 20| 20| 40|\n| 20| 22| 21|\n| 30| 32| 41|\n| 50| 22| 51|\n| 20| 12| 61|\n| 20| 22| 50|\n| 50| 52| 51|\n| 80| 80| 80|\n+---+---+---+\n\n"
     ]
    }
   ],
   "source": [
    "data=[(\"10\",\"10\",\"10\"),(\"11\",\"11\",\"11\"),(\"30\",\"32\",\"30\"),(\"40\",\"40\",\"40\"),(\"20\",\"20\",\"21\"),(\"21\",\"21\",\"21\"),(\"20\",\"22\",\"21\"),(\"20\",\"20\",\"40\"),(\"20\",\"22\",\"21\"),(\"30\",\"32\",\"41\"),(\"50\",\"22\",\"51\"),(\"20\",\"12\",\"61\"),(\"20\",\"22\",\"50\"),(\"50\",\"52\",\"51\"),(\"80\",\"80\",\"80\")]\n",
    "schema =[\"A\",\"B\",\"C\"]\n",
    "df=spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "944339d9-e961-4aab-8bdc-ffff23156b2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n| triangle_type|\n+--------------+\n|   Equilateral|\n|   Equilateral|\n|     Isosceles|\n|   Equilateral|\n|     Isosceles|\n|   Equilateral|\n|       Scalene|\n|Not A Triangle|\n|       Scalene|\n|       Scalene|\n|       Scalene|\n|Not A Triangle|\n|Not A Triangle|\n|       Scalene|\n|   Equilateral|\n+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when,col\n",
    "\n",
    "df.withColumn(\"triangle_type\",\n",
    "    when((col(\"A\") + col(\"B\") <= col(\"C\")) | (col(\"A\") + col(\"C\") <= col(\"B\")) | (col(\"B\") + col(\"C\") <= col(\"A\")),\"Not A Triangle\")\n",
    "        .when((col(\"A\") == col(\"B\")) & (col(\"B\") == col(\"C\")),\"Equilateral\")\n",
    "            .when((col(\"A\") == col(\"B\")) | (col(\"A\") == col(\"C\")) | (col(\"B\") == col(\"C\")),\"Isosceles\").\n",
    "                otherwise(\"Scalene\")).select(\"triangle_type\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day 03 (Pyspark)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
