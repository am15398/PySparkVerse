{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12ad15d6-8a45-46c8-af5b-6edc383a9d46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# DataBricks Cluster \n",
    "- In Databricks, clusters are the compute engines that run your code. Databricks supports several types of clusters, each optimized for specific use cases.\n",
    "\n",
    "## ðŸ§± Databricks Cluster Types and Instance Pool (Table Format)\n",
    "\n",
    "| **Cluster Type**                    | **Details and Use Cases**                                                                                                                                                      | **Detail**                                                                                                                                                                        |\n",
    "|------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Interactive Cluster (All-Purpose)** | - **Best For:** Notebooks, development, exploration, ML experiments  <br> - **Lifespan:** Manual start/stop  <br> - **UI Access:** Workspace â†’ Compute                                    | Provisioned compute used to analyze data in notebooks. You can create, terminate, and restart this compute using the UI, CLI, or REST API. mainly for development |\n",
    "| **Job Cluster**                    | - **Usage:** Scheduled ETL or Batch jobs and workflows  <br> - **Lifespan:** Auto-created at job start, terminated after job completion  <br> - **Provisioned via:** Jobs API, UI         | Automatically created by Databricks when a job starts. Automatically terminates when the job finishes. Mainly used by prod jobs  |\n",
    "| **SQL Warehouse** (SQL Endpoint)   | - **Usage:** BI dashboards, SQL editor queries  <br> - **Photon-powered:** Yes (by default)  <br> - Auto-scaling and on-demand start  | Used to run SQL queries in dashboards or interactive notebooks.  |\n",
    "| **Shared Cluster**                 | - Manually configured to allow multiple users or jobs to share a single cluster                                                                                                 | Option available under All-Purpose cluster to allow multiple users to share the same cluster.                                                                                      |\n",
    "| **Single Node Cluster**           | - **Usage:** Non-distributed jobs, model training, file processing  <br> - **Configuration:** Enable \"Single node\" in cluster settings      | Created under Unrestricted policy. Suitable for lightweight and simple jobs.       |\n",
    "| **Delta Live Tables Cluster**      | - **Usage:** DLT pipelines (ETL workflows / managed pipelines)  <br> - **Managed Automatically:** Databricks provisions and scales cluster                                              | Managed via **Workflows â†’ Delta Live Tables**. Cluster mode options include: <br> - Default (Managed) <br> - Photon <br> - Single-node.         |\n",
    "| **Photon Cluster**                 | - **Usage:** Accelerated SQL performance  <br> - **Compatibility:** Spark SQL, Databricks SQL  <br> - **Hardware:** Optimized for x86 vectorized execution                                 | High-performance engine (Photon) used for speeding up SQL query execution. Enabled by default in SQL Warehouses and configurable in clusters.                                     |\n",
    "| **Serverless Cluster**            | - **Usage:** Auto-scaling and zero management  <br> - **Benefit:** Pay only for execution time  <br> - **Note:** Availability depends on region/plan     | Databricks provides one low-config serverless cluster per workspace for quick Python or SQL tasks. No manual setup required.    |\n",
    "| **Instance Pool**                 | - **Purpose:** Speed up cluster startup, improve efficiency  <br> - **Use with:** All-purpose and job clusters  <br> - **Benefit:** Lower cost, faster jobs, better control                | Pre-creates and manages VMs that can be reused by multiple clusters to reduce startup time and optimize cost.                                                                     |\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_cluster",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
